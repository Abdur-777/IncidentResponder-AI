name: Weekly Crawl + Reindex (_hash_index)

on:
  schedule:
    - cron: "0 3 * * 1"   # Mondays 03:00 UTC
  workflow_dispatch:

concurrency:
  group: refresh-crawl-reindex
  cancel-in-progress: false

jobs:
  refresh:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # Auth to GCP (ADC for python client libs)
      - name: Google Auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_JSON }}

      - name: Crawl Wyndham PDFs to GCS
        env:
          GCS_BUCKET: civreply-data
          DOCS_PREFIX: policies/wyndham/crawl
          CRAWL_BASE: https://www.wyndham.vic.gov.au
        run: |
          python scripts/crawl_site.py wyndham \
            --base "$CRAWL_BASE" \
            --bucket "$GCS_BUCKET" \
            --docs-prefix "$DOCS_PREFIX" \
            --file-exts .pdf

      - name: Rebuild FAISS index at policies/{slug}/_hash_index
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          GCS_BUCKET: civreply-data
          DOC_PREFIX: policies/{slug}
          INDEX_PREFIX: policies/{slug}/_hash_index
        run: |
          python scripts/rebuild_index.py wyndham
